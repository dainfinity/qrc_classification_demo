{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Reservoir Computing (Fujii-Nakajima) で時系列2値分類\n",
    "\n",
    "このノートブックは **Google Colab 実行**を前提に、\n",
    "- GitHubからリポジトリをclone\n",
    "- 可視化コードは外部モジュール (`src/spin_viz.py`) をimport\n",
    "- QRC計算本体はNotebook内に記述\n",
    "という構成です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Colabセットアップ (GitHub clone + install)\n",
    "\n",
    "`REPO_URL` を確認して実行してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/dainfinity/qrc_classification_demo.git\"\n",
    "REPO_DIR = \"qrc_classification_demo\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"requirements-colab.txt\"], check=True)\n",
    "\n",
    "repo_root = pathlib.Path.cwd()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(\"Working directory:\", repo_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データ読み込み\n",
    "\n",
    "固定長系列 `L` の2値分類データをCSVから読み込みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import repeat\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import expm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "\n",
    "USE_PARALLEL = True\n",
    "N_WORKERS = min(4, os.cpu_count() or 2)\n",
    "print(f\"USE_PARALLEL={USE_PARALLEL}, N_WORKERS={N_WORKERS}, SEED={SEED}\")\n",
    "\n",
    "train_X_raw = pd.read_csv(\"data/train_X.csv\").values.astype(np.float64)\n",
    "train_y = pd.read_csv(\"data/train_y.csv\")[\"label\"].values.astype(int)\n",
    "test_X_raw = pd.read_csv(\"data/test_X.csv\").values.astype(np.float64)\n",
    "test_y = pd.read_csv(\"data/test_y.csv\")[\"label\"].values.astype(int)\n",
    "\n",
    "M_train, L = train_X_raw.shape\n",
    "M_test, L2 = test_X_raw.shape\n",
    "assert L == L2\n",
    "print(f\"Train: {train_X_raw.shape}, Test: {test_X_raw.shape}, sequence length L={L}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 多体系スピン可視化とハイパーパラメータ\n",
    "\n",
    "`src/spin_viz.py` のウィジェットで以下を設定します。\n",
    "- トポロジー (全結合 / 1D鎖 / 2D近接)\n",
    "- スピン数 `N`\n",
    "- 結合幅 `J width`\n",
    "- 横磁場 `h field`\n",
    "\n",
    "Fujii-Nakajimaスキームでは、自由パラメータは主に `J width`, `h field`, `tau(時間発展長)` です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spin_viz import build_spin_control_panel\n",
    "\n",
    "panel, controls = build_spin_control_panel(default_n=6, seed=SEED)\n",
    "display(panel)\n",
    "\n",
    "tau_slider = widgets.FloatSlider(value=0.20, min=0.02, max=1.00, step=0.02, description=\"tau\")\n",
    "display(tau_slider)\n",
    "\n",
    "print(\"計算前に上のパラメータを調整してください。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fujii-Nakajima スキームの数式\n",
    "\n",
    "入力は各時刻で必ず `[0,1]` にスケーリングしてから注入します。\n",
    "\n",
    "1. 入力スケーリング\n",
    "\\[\n",
    "\tilde{u}_t = \\mathrm{clip}\\left(\frac{u_t-u_{\\min}}{u_{\\max}-u_{\\min}},\\,0,\\,1\right)\n",
    "\\]\n",
    "\n",
    "2. Ry入力注入（入力サイトを毎時刻初期化）\n",
    "\\[\n",
    "|\\psi_{\\mathrm{in}}(\tilde{u}_t)\rangle = R_y\\!\\left(2\u0007rcsin\\sqrt{\tilde{u}_t}\right)|0\rangle\n",
    "= \\sqrt{1-\tilde{u}_t}|0\rangle + \\sqrt{\tilde{u}_t}|1\rangle\n",
    "\\]\n",
    "\n",
    "3. 合成状態を作って時間発展\n",
    "\\[\n",
    "\rho_t^{\\mathrm{in}} = |\\psi_{\\mathrm{in}}\rangle\\langle\\psi_{\\mathrm{in}}|,\\quad\n",
    "\rho_t^{\\mathrm{joint}} = \rho_t^{\\mathrm{in}} \\otimes \rho_{t-1}^{\\mathrm{res}}\n",
    "\\]\n",
    "\\[\n",
    "U = e^{-iH\tau},\\quad\n",
    "\rho_t' = U\rho_t^{\\mathrm{joint}}U^\\dagger\n",
    "\\]\n",
    "\n",
    "4. 観測とリセット\n",
    "\\[\n",
    "r_t^{(i)} = \\mathrm{Tr}(\rho_t' Z_i),\\quad i=0,\\dots,N-1\n",
    "\\]\n",
    "\\[\n",
    "\rho_t^{\\mathrm{res}} = \\mathrm{Tr}_{\\mathrm{in}}(\rho_t')\n",
    "\\]\n",
    "\n",
    "ここで\n",
    "\\[\n",
    "H = \\sum_{(i,j)\\in E}J_{ij}Z_iZ_j + h\\sum_{i=0}^{N-1}X_i\n",
    "\\]\n",
    "で、`E` は選択トポロジーで決まります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMA_X = np.array([[0, 1], [1, 0]], dtype=np.complex128)\n",
    "SIGMA_Z = np.array([[1, 0], [0, -1]], dtype=np.complex128)\n",
    "IDENTITY = np.eye(2, dtype=np.complex128)\n",
    "\n",
    "\n",
    "def kron_many(ops):\n",
    "    out = np.array([[1.0 + 0.0j]])\n",
    "    for op in ops:\n",
    "        out = np.kron(out, op)\n",
    "    return out\n",
    "\n",
    "\n",
    "def site_operator(n_spins, site, op):\n",
    "    mats = [IDENTITY] * n_spins\n",
    "    mats[site] = op\n",
    "    return kron_many(mats)\n",
    "\n",
    "\n",
    "def zz_operator(n_spins, i, j):\n",
    "    mats = [IDENTITY] * n_spins\n",
    "    mats[i] = SIGMA_Z\n",
    "    mats[j] = SIGMA_Z\n",
    "    return kron_many(mats)\n",
    "\n",
    "\n",
    "def grid_shape(n_spins):\n",
    "    rows = int(np.floor(np.sqrt(n_spins)))\n",
    "    while rows > 1 and n_spins % rows != 0:\n",
    "        rows -= 1\n",
    "    cols = int(np.ceil(n_spins / rows))\n",
    "    return rows, cols\n",
    "\n",
    "\n",
    "def build_edges(n_spins, topology):\n",
    "    if topology == \"all_to_all\":\n",
    "        return [(i, j) for i in range(n_spins) for j in range(i + 1, n_spins)]\n",
    "    if topology == \"chain_1d\":\n",
    "        return [(i, i + 1) for i in range(n_spins - 1)]\n",
    "    if topology == \"grid_2d\":\n",
    "        rows, cols = grid_shape(n_spins)\n",
    "        edges = []\n",
    "        for idx in range(n_spins):\n",
    "            r, c = divmod(idx, cols)\n",
    "            right = idx + 1\n",
    "            down = idx + cols\n",
    "            if c + 1 < cols and right < n_spins:\n",
    "                edges.append((idx, right))\n",
    "            if r + 1 < rows and down < n_spins:\n",
    "                edges.append((idx, down))\n",
    "        return edges\n",
    "    raise ValueError(f\"Unknown topology: {topology}\")\n",
    "\n",
    "\n",
    "def build_hamiltonian_and_observables(n_spins, topology, j_width, h_field, seed=SEED):\n",
    "    x_ops = [site_operator(n_spins, i, SIGMA_X) for i in range(n_spins)]\n",
    "    z_ops = [site_operator(n_spins, i, SIGMA_Z) for i in range(n_spins)]\n",
    "    edges = build_edges(n_spins, topology)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dim = 2 ** n_spins\n",
    "    h_int = np.zeros((dim, dim), dtype=np.complex128)\n",
    "    for (i, j) in edges:\n",
    "        jij = rng.uniform(-j_width, j_width)\n",
    "        h_int += jij * zz_operator(n_spins, i, j)\n",
    "\n",
    "    h_field_term = np.zeros((dim, dim), dtype=np.complex128)\n",
    "    for i in range(n_spins):\n",
    "        h_field_term += h_field * x_ops[i]\n",
    "\n",
    "    h0 = h_int + h_field_term\n",
    "    return h0, z_ops\n",
    "\n",
    "\n",
    "def minmax_scale_to_unit_interval(x, u_min, u_max):\n",
    "    if abs(u_max - u_min) < 1e-12:\n",
    "        return np.zeros_like(x)\n",
    "    z = (x - u_min) / (u_max - u_min)\n",
    "    return np.clip(z, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def pure_input_density_from_u(u01):\n",
    "    u01 = float(np.clip(u01, 0.0, 1.0))\n",
    "    amp0 = np.sqrt(1.0 - u01)\n",
    "    amp1 = np.sqrt(u01)\n",
    "    psi = np.array([amp0, amp1], dtype=np.complex128)\n",
    "    return np.outer(psi, psi.conj())\n",
    "\n",
    "\n",
    "def partial_trace_input_qubit(rho_joint, n_spins):\n",
    "    d_res = 2 ** (n_spins - 1)\n",
    "    rho4 = rho_joint.reshape(2, d_res, 2, d_res)\n",
    "    return np.trace(rho4, axis1=0, axis2=2)\n",
    "\n",
    "\n",
    "def sequence_to_state_matrix_fn(sequence_raw, params):\n",
    "    n_spins = params[\"n_spins\"]\n",
    "    topology = params[\"topology\"]\n",
    "    j_width = params[\"j_width\"]\n",
    "    h_field = params[\"h_field\"]\n",
    "    tau = params[\"tau\"]\n",
    "    seed = params[\"seed\"]\n",
    "    u_min = params[\"u_min\"]\n",
    "    u_max = params[\"u_max\"]\n",
    "\n",
    "    h0, z_ops = build_hamiltonian_and_observables(n_spins, topology, j_width, h_field, seed=seed)\n",
    "    u_op = expm(-1j * h0 * tau)\n",
    "    u_dag = u_op.conj().T\n",
    "\n",
    "    d_res = 2 ** (n_spins - 1)\n",
    "    rho_res = np.zeros((d_res, d_res), dtype=np.complex128)\n",
    "    rho_res[0, 0] = 1.0 + 0.0j\n",
    "\n",
    "    sequence = minmax_scale_to_unit_interval(np.asarray(sequence_raw, dtype=np.float64), u_min, u_max)\n",
    "    states = np.zeros((len(sequence), n_spins), dtype=np.float64)\n",
    "\n",
    "    for t, u_t in enumerate(sequence):\n",
    "        rho_in = pure_input_density_from_u(u_t)\n",
    "        rho_joint = np.kron(rho_in, rho_res)\n",
    "        rho_evolved = u_op @ rho_joint @ u_dag\n",
    "\n",
    "        for i in range(n_spins):\n",
    "            states[t, i] = float(np.real(np.trace(rho_evolved @ z_ops[i])))\n",
    "\n",
    "        rho_res = partial_trace_input_qubit(rho_evolved, n_spins)\n",
    "\n",
    "    return states\n",
    "\n",
    "\n",
    "def build_matrices_for_dataset(X_raw, params, use_parallel=True, n_workers=2):\n",
    "    if use_parallel:\n",
    "        try:\n",
    "            with ProcessPoolExecutor(max_workers=n_workers) as ex:\n",
    "                mats = list(ex.map(sequence_to_state_matrix_fn, X_raw, repeat(params)))\n",
    "            return np.stack(mats, axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Parallel execution failed ({e}), fallback to sequential.\")\n",
    "\n",
    "    mats = [sequence_to_state_matrix_fn(seq, params) for seq in X_raw]\n",
    "    return np.stack(mats, axis=0)\n",
    "\n",
    "\n",
    "def predict_1nn_frobenius(train_mats, train_labels, test_mats):\n",
    "    preds = []\n",
    "    for test_mat in test_mats:\n",
    "        diffs = train_mats - test_mat[None, :, :]\n",
    "        dists = np.linalg.norm(diffs, ord=\"fro\", axis=(1, 2))\n",
    "        nn_idx = int(np.argmin(dists))\n",
    "        preds.append(int(train_labels[nn_idx]))\n",
    "    return np.array(preds, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 実行（入力スケーリング → リザバー行列化 → 1-NN）\n",
    "\n",
    "- 入力は必ず `[0,1]` にスケーリング\n",
    "- train/testそれぞれでリザバー状態行列を作成\n",
    "- 行列を保存して、Frobenius距離の1-NNで評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力スケーリング用の統計量は train から取得\n",
    "u_min = float(train_X_raw.min())\n",
    "u_max = float(train_X_raw.max())\n",
    "print(f\"Input scaling range from train: u_min={u_min:.4f}, u_max={u_max:.4f}\")\n",
    "\n",
    "reservoir_params = {\n",
    "    \"n_spins\": int(controls[\"n_spins\"].value),\n",
    "    \"topology\": controls[\"topology\"].value,\n",
    "    \"j_width\": float(controls[\"j_width\"].value),\n",
    "    \"h_field\": float(controls[\"h_field\"].value),\n",
    "    \"tau\": float(tau_slider.value),\n",
    "    \"seed\": SEED,\n",
    "    \"u_min\": u_min,\n",
    "    \"u_max\": u_max,\n",
    "}\n",
    "\n",
    "print(\"Reservoir params (Fujii-Nakajima):\")\n",
    "for k, v in reservoir_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "train_mats = build_matrices_for_dataset(\n",
    "    train_X_raw, reservoir_params, use_parallel=USE_PARALLEL, n_workers=N_WORKERS\n",
    ")\n",
    "test_mats = build_matrices_for_dataset(\n",
    "    test_X_raw, reservoir_params, use_parallel=USE_PARALLEL, n_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "np.save(\"data/train_reservoir_matrices.npy\", train_mats)\n",
    "np.save(\"data/test_reservoir_matrices.npy\", test_mats)\n",
    "print(\"saved: data/train_reservoir_matrices.npy\")\n",
    "print(\"saved: data/test_reservoir_matrices.npy\")\n",
    "\n",
    "pred = predict_1nn_frobenius(train_mats, train_y, test_mats)\n",
    "acc = (pred == test_y).mean()\n",
    "print(f\"1-NN accuracy (Frobenius): {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 注意\n",
    "\n",
    "この実装は **時間多重化なし** です。特徴量は各時刻で1回観測した `N` 次元ベクトルのみを使っています。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}